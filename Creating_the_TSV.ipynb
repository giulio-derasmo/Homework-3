{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7e88ad-2d22-4fcd-8299-7a2b60ff3b19",
   "metadata": {},
   "source": [
    "# Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378a4f6-48f4-478b-8ff7-e4ceba13d282",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82485d1c-5c9e-4787-af3c-579734e4dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20106eec-0ae7-4566-89a6-b2b3b8a2b938",
   "metadata": {},
   "source": [
    "# Iterating over the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779988a4-c82a-45c5-9551-2b37fc0d6107",
   "metadata": {},
   "source": [
    "Define a function to scrab the anime (incomplite)\n",
    "\n",
    "* anime_info: is a list that store the information of the anime in order of attributes list (the column of the dataframe)\n",
    "\n",
    "Than the anime_info is store inside the __list_of_anime__ a list that store all the anime_info list. Than is pass to a daframe and create the tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c7bc2c00-b903-40ae-9ee1-a30b20f985a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(dates):\n",
    "# input: date >> a string of various format:\n",
    "#            1)    Month day, Year to Month day, Year\n",
    "#            2)    Month day, Year\n",
    "#            3)    Year to Year\n",
    "\n",
    "    # if we are in case 1 and 3\n",
    "    if re.search(\"to\", dates):\n",
    "        clean_date = [re.sub(\"\\n\",\"\",date).strip() for date in dates.split(\"to\")]\n",
    "        # if we are in case 1\n",
    "        if re.search(\",\",clean_date[0]):\n",
    "            # %b = for abbreviate month\n",
    "            release = datetime.strptime(re.sub(\",\",\"\",clean_date[0]), '%b %d %Y')\n",
    "            # not everyone as end date (for example: still airing)\n",
    "            try:\n",
    "                end = datetime.strptime(re.sub(\",\",\"\",clean_date[1]), '%b %d %Y')\n",
    "            except:\n",
    "                end = None\n",
    "        # else we are in case 3\n",
    "        else:\n",
    "            release = datetime.strptime(clean_date[0], '%Y')\n",
    "            end = datetime.strptime(clean_date[1], '%Y')\n",
    "    # else we are in case 2\n",
    "    else:\n",
    "        clean_date = dates.replace(\",\",\"\").strip()\n",
    "        release = datetime.strptime(clean_date, '%b %d %Y')\n",
    "        end = None\n",
    "        \n",
    "    return release, end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bb7d6-c6db-4617-8407-f1d55b895f69",
   "metadata": {},
   "source": [
    "The function scrabbing_anime takes the __INFORMATION__ info of the anime + the __TITLE__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087a425-cc98-4383-9955-98fdf4687e9d",
   "metadata": {},
   "source": [
    "I will divide the scrubs in part:\n",
    "* scrab 1: Title, Type, nEpisode, Realease / End date\n",
    "* scrab 2: Score, Ranked, Poplarity, Members\n",
    "* scrab 3\n",
    "* scrab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8a1d6965-db99-4848-873c-91d3f3029af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrabbing_anime1(soup, anime_info):\n",
    "    # Anime Title\n",
    "    # <h1 class=\"title-name h1_bold_none\"><strong>Fullmetal Alchemist: Brotherhood</strong></h1>\n",
    "    title = str(soup.find(\"h1\", attrs = {\"class\": \"title-name h1_bold_none\"}).string)\n",
    "    # Taken Information\n",
    "    # <h2>Information</h2> , there are a lot of h2 so i specify is written >>inside a div<<\n",
    "    for h2 in soup.select('h2:has(+div)'):\n",
    "        # I want the <h2> Information </h2> only\n",
    "        if h2.text == \"Information\" :\n",
    "            # iter over the next 4 <div> of Information, i go this way because\n",
    "            # 1) i want to skip the \"Status\", is the 3th div\n",
    "            # 2) more clear\n",
    "            for inform in h2.find_all_next(\"div\", attrs = {\"class\": \"spaceit_pad\"}, limit = 4):\n",
    "                if inform.contents[1].string == \"Type:\":\n",
    "                    Type = inform.get_text(separator=\" \", strip=True).split()[-1] \n",
    "                if inform.contents[1].string == \"Episodes:\":\n",
    "                    nEpisodes = inform.get_text(separator=\" \", strip=True).split()[-1]\n",
    "                if inform.contents[1].string == \"Aired:\":\n",
    "                    # not always the date of start/end is store\n",
    "                    # i can have \"still airing\" or NA value\n",
    "                    try:\n",
    "                        # take the string of where the data is store\n",
    "                        date = inform.contents[2]\n",
    "                        release_date, end_date = parse_time(date)\n",
    "                    except:\n",
    "                        release_date = None\n",
    "                        end_date = None\n",
    "    \n",
    "    # save on anime info\n",
    "    anime_info.extend((title,Type,nEpisodes,release_date,end_date))\n",
    "    return anime_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "701b754f-b931-40f2-95ab-3924bdc751c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrabbing:\n",
    "# Score, Ranked, Poplarity, Members\n",
    "def scrabbing_anime2(soup, anime_info):\n",
    "    #animeNumMembers\n",
    "    members = soup.find(\"span\",{\"class\":\"numbers members\"})\n",
    "    members = int(members.find('strong').contents[0].replace(\",\",\"\"))\n",
    "    #animeScore\n",
    "    score = soup.find(\"div\", attrs = {\"class\": \"fl-l score\", \"data-title\": \"score\"})\n",
    "    try:\n",
    "        # is a number\n",
    "        score = float(score.contents[0].string)\n",
    "    except:\n",
    "        # is N/A\n",
    "        score = None\n",
    "    #animeRank\n",
    "    rank = soup.find(\"span\",{\"class\":\"numbers ranked\"})\n",
    "    try:\n",
    "        #rank is a number\n",
    "        rank =  int(rank.find('strong').contents[0].replace(r\"#\", ' '))\n",
    "    except:\n",
    "        # anime have a rank of NA\n",
    "        rank = None\n",
    "    #animePopularity  \n",
    "    popularity = soup.find(\"span\",{\"class\":\"numbers popularity\"})\n",
    "    popularity = int(popularity.find('strong').contents[0].replace(r\"#\", ' '))\n",
    "\n",
    "    # save on anime info\n",
    "    anime_info.extend((members, score, rank, popularity))\n",
    "        \n",
    "    return anime_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9b731757-2750-416b-8702-102854d99cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anime characters and voices, synopsis\n",
    "def scrabbing_anime3(soup, anime_info):\n",
    "    # Characters and voices doesn't exist always\n",
    "    try:\n",
    "        tag = soup.find_all(\"div\", {\"class\": \"detail-characters-list clearfix\"})\n",
    "        # there is some anime with empty attributes\n",
    "        characters =  tag[0].find_all(\"h3\", {\"class\": \"h3_characters_voice_actors\"})\n",
    "        for i,char in enumerate(characters):\n",
    "            characters[i] = char.get_text()\n",
    "        voices = tag[0].find_all(\"td\", {\"class\": \"va-t ar pl4 pr4\"})\n",
    "        for i,voice in enumerate(voices):\n",
    "            voices[i] = voice.get_text().replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        characters = None\n",
    "        voices = None\n",
    "    #synopsis (description)\n",
    "    synopsis = str(soup.find(\"p\", attrs = {\"itemprop\": \"description\"}).text)\n",
    "    # related anime\n",
    "    try:         \n",
    "        related = soup.find_all(\"td\", {\"width\": \"100%\",  \"class\": \"borderClass\"})\n",
    "        for i,anime in enumerate(related):\n",
    "            related[i] = anime.get_text()\n",
    "        # only unique value\n",
    "        related = list(set(related))\n",
    "    except:\n",
    "        related = None\n",
    "        \n",
    "    # save on anime info\n",
    "    anime_info.extend((synopsis,related,characters, voices))\n",
    "    return anime_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c56f32-1a89-4585-869a-f8f0269eefec",
   "metadata": {},
   "source": [
    "# Try one anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "082fb470-8b5e-4118-b38d-1a427f7f5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = [\"animeTitle\", \"animeType\", \"animeNumEpisode\",\"releaseDate\",\"endDate\",\"animeNumMembers\",\"animeScore\",\"animeRank\",\n",
    "         \"animePopularity\",\"animeDescription\",\"animeRelated\",\"animeCharacters\",\"animeVoices\"]\n",
    "\n",
    "list_of_anime = []\n",
    "#html_name = r\"./Folder_with_page/page43/anime_2110.html\"\n",
    "html_name = r\"./Folder_with_page/page1/anime_1.html\"\n",
    "\n",
    "with open(html_name, \"r\",  encoding='utf-8') as fp:\n",
    "    soup = BeautifulSoup(fp, \"html.parser\")\n",
    "\n",
    "anime_info = []\n",
    "anime_info + scrabbing_anime1(soup, anime_info)\n",
    "anime_info + scrabbing_anime2(soup, anime_info)\n",
    "anime_info + scrabbing_anime3(soup, anime_info)\n",
    "\n",
    "\n",
    "# scrab of the anime finish\n",
    "list_of_anime.append(anime_info)\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(list_of_anime, columns = attrs)\n",
    "# Creating the tsv file\n",
    "df.to_csv('anime1.tsv', index = False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "88bf9209-c455-4dc3-9fae-5e475af76291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Fullmetal Alchemist: Brotherhood',\n",
       "  'TV',\n",
       "  '64',\n",
       "  datetime.datetime(2009, 4, 5, 0, 0),\n",
       "  datetime.datetime(2010, 7, 4, 0, 0),\n",
       "  2676066,\n",
       "  9.16,\n",
       "  1,\n",
       "  3,\n",
       "  'After a horrific alchemy experiment goes wrong in the Elric household, brothers Edward and Alphonse are left in a catastrophic new reality. Ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. Instead, they suffered brutal personal loss: Alphonse\\'s body disintegrated while Edward lost a leg and then sacrificed an arm to keep Alphonse\\'s soul in the physical realm by binding it to a hulking suit of armor.\\n\\n\\nThe brothers are rescued by their neighbor Pinako Rockbell and her granddaughter Winry. Known as a bio-mechanical engineering prodigy, Winry creates prosthetic limbs for Edward by utilizing \"automail,\" a tough, versatile metal used in robots and combat armor. After years of training, the Elric brothers set off on a quest to restore their bodies by locating the Philosopher\\'s Stone—a powerful gem that allows an alchemist to defy the traditional laws of Equivalent Exchange.\\n\\n\\nAs Edward becomes an infamous alchemist and gains the nickname \"Fullmetal,\" the boys\\' journey embroils them in a growing conspiracy that threatens the fate of the world.\\n\\n\\n[Written by MAL Rewrite]',\n",
       "  ['Fullmetal Alchemist: Brotherhood - 4-Koma Theater',\n",
       "   'Fullmetal Alchemist',\n",
       "   'Fullmetal Alchemist: Brotherhood Specials, Fullmetal Alchemist: The Sacred Star of Milos'],\n",
       "  ['Elric, Edward',\n",
       "   'Elric, Alphonse',\n",
       "   'Mustang, Roy',\n",
       "   'Hughes, Maes',\n",
       "   'Greed',\n",
       "   'Hawkeye, Riza',\n",
       "   'Yao, Ling',\n",
       "   'Armstrong, Alex Louis',\n",
       "   'Rockbell, Winry',\n",
       "   'Armstrong, Olivier Mira'],\n",
       "  ['Park, RomiJapanese',\n",
       "   'Kugimiya, RieJapanese',\n",
       "   'Miki, ShinichiroJapanese',\n",
       "   'Fujiwara, KeijiJapanese',\n",
       "   'Nakamura, YuuichiJapanese',\n",
       "   'Orikasa, FumikoJapanese',\n",
       "   'Miyano, MamoruJapanese',\n",
       "   'Utsumi, KenjiJapanese',\n",
       "   'Takamoto, MegumiJapanese',\n",
       "   'Soumi, YoukoJapanese']]]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "88e935b1-21e0-4695-b65e-40d6839782e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animeTitle                  object\n",
       "animeType                   object\n",
       "animeNumEpisode             object\n",
       "releaseDate         datetime64[ns]\n",
       "endDate             datetime64[ns]\n",
       "animeNumMembers              int64\n",
       "animeScore                 float64\n",
       "animeRank                    int64\n",
       "animePopularity              int64\n",
       "animeDescription            object\n",
       "animeRelated                object\n",
       "animeCharacters             object\n",
       "animeVoices                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf703c-5ce8-42da-8295-57fee022342e",
   "metadata": {},
   "source": [
    "# For all the anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4548a370-7b90-4d2d-a6d5-95ad568d0501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.70s/it]\n"
     ]
    }
   ],
   "source": [
    "attrs = [\"animeTitle\", \"animeType\", \"animeNumEpisode\",\"releaseDate\",\"endDate\",\"animeNumMembers\",\"animeScore\",\"animeRank\",\n",
    "         \"animePopularity\",\"animeDescription\",\"animeRelated\",\"animeCharacters\",\"animeVoices\"]\n",
    "\n",
    "list_of_anime = []\n",
    "# from page 1 to 130\n",
    "for page in tqdm(range(0,1)):\n",
    "    folder = \"./Folder_with_page/page\"+str(page+1)\n",
    "    for i,anime in enumerate(os.listdir(folder)):\n",
    "        with open(folder + \"/\" + anime, \"r\",  encoding='utf-8') as fp:\n",
    "            soup = BeautifulSoup(fp, \"html.parser\")\n",
    "        anime_info = []\n",
    "        anime_info + scrabbing_anime1(soup, anime_info)\n",
    "        anime_info + scrabbing_anime2(soup, anime_info)\n",
    "        anime_info + scrabbing_anime3(soup, anime_info)\n",
    "        \n",
    "        # Creating the DataFrame\n",
    "        df = pd.DataFrame([anime_info], columns = attrs)\n",
    "        # Creating the tsv file\n",
    "        name = re.sub(\".html\",\"\",anime)\n",
    "        df.to_csv(\"./tsv_anime/\"+name+\".tsv\", index = False, sep = \"\\t\")\n",
    "    \n",
    "        #cheack all the entries\n",
    "        list_of_anime.append(anime_info)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4ee24-b9ce-4ec0-9c84-3140d9307f79",
   "metadata": {},
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7023074d-d394-420f-9c4a-d12a71b245d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame\n",
    "df_total = pd.DataFrame(list_of_anime, columns = attrs)\n",
    "# Creating the tsv file\n",
    "df_total.to_csv(\"./anime_totale.tsv\", index = False, sep = \"\\t\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c523ee-ffb3-4f6a-9573-af7ee7ec940f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
